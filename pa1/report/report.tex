% by LaTeX newbie
\documentclass[letterpaper]{article}

\author{Chinmay Kulkarni, Will Zou}
\title{Assignment 1}

\begin{document}
\maketitle

\section{Word alignment}
We implemented PMI and IBM Models 1 and 2 for translation word alignment. The models were trained on 10k sentences in each source language, and ran for 100 iterations each. The reported numbers are AER evaluated on the test set of the particular language pair. 
\subsection{PMI Model}
\subsubsection{Error analysis} % (fold)
\label{ssub:error_analysis}

\textbf{Assumptions on word order} The PMI model only counts the number of sentences where words appear together. So, it makes no assumptions about word order, but also learns very little-- in particular, since it can only use each sentence pair as an independent data point. 

Therefore, it cannot learn word alignments for one pair of words based on high-confidence alignments for other words (like the IBM models).

\textbf{Common words, uncommon words} Common words in language pairs are confused easily: the word \textit{et} in French is likely to appear in sentences whose English translations contain words like \textit{and}, \textit{in}, \textit{of} etc. Since PMI has no way to disambiguate these,  \textit{and}, \textit{in}, \textit{of} are all likely to align to \textit{et}.

\textbf{Good alignments} when words are relatively uncommon, and have few synonyms in each language (e.g. \textit{ministre} and \textit{minister})

\textbf{Aligning too many words to a word}: Because the PMI model depends on sentence counts, too many words get aligned to common words.

\subsection{IBM Model 1} % (fold)
\label{sub:ibm_model_1}

The IBM Model is much better at aligning words. In particular, when words have a single translation, this model is able to learn such an alignment even with few training examples. For instance, with 200 training sentences on the dev set, it finds: $ bravo \rightarrow$ [hear : 0.9577806528910323, , : 0.021...], a reasonably high confidence match.

However, when words are used together, the model is unable to discriminate. With the same 200 training sentences, $De \rightarrow$ [OFFICE : 0.3333466831184435, oaths : 0.3333466831184435, OF : 0.33330663376311387]. I suspect this is because oaths-of-office is translated as a single phrase and the model is unable to distinguish between the french equivalents with this training set.

My alignment model goes left-to-right in the target sentence, so in a sentence like ``oaths of office'', the three French words may be mapped to ``oaths''.  

\subsubsection{Sensitivity to word order} % (fold)
\label{ssub:sensitivity_to_word_order}
Like PMI, the model is insensitive to word order. 
% subsubsection sensitivity_to_word_order (end)


With 100 iterations and 10,000 training sentences, results improve. Many of the words that were not distinguishable with a smaller dataset because they only appeared together (like ``oaths of office'') are now better separated. ``de'' aligns to ``of'' more strongly, for example.

% subsection ibm_model_1 (end)
  
% subsubsection error_analysis (end)
\begin{table}[tb]
	\caption{AER Results}
	\label{fig:AERResults}
	\begin{center}
		\begin{tabular}{lccc}

		\hline
		\textbf{~} & \textbf{French-English} & \textbf{Hindi English} & \textbf{Chinese English} \\
		\hline
			 PMI & 0.1818/0.1114/0.8450 & 0.0833/0.0646/0.9272 & 0.0779/0.0456/0.9425 \\
			 IBM Model 1(200 sentences) & 0.3343/0.2456/0.6941 & 0.3205/0.3011/0.6895 & \\
			 IBM Model 1 (10,000 sentences) &  &  \\
		\hline

		\hline
		\end{tabular}
	\end{center}
\end{table}

\subsection{IBM Model 1}


\end{document}